{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Load president Washington's 1789 inaugural address</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.corpus import inaugural\n",
    "Washington = inaugural.words('1789-Washington.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>2. Count the total number of words, and report the number</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1538\n"
     ]
    }
   ],
   "source": [
    "number_of_words = len(Washington)\n",
    "print(number_of_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Find the ten most frequent words, and report them in a table with their counts</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   words  counts\n",
      "0    the     115\n",
      "1     of      71\n",
      "2      ,      70\n",
      "3    and      48\n",
      "4     to      47\n",
      "5  which      36\n",
      "6     in      28\n",
      "7      I      23\n",
      "8     be      23\n",
      "9      .      22\n"
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(Washington)\n",
    "ten_freq_table = pd.DataFrame(fdist.most_common(10))\n",
    "ten_freq_table.columns = ['words', 'counts']\n",
    "print(ten_freq_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>4. Load president Obama's 1789 inaugural address</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2726\n"
     ]
    }
   ],
   "source": [
    "Obama = inaugural.words('2009-Obama.txt')\n",
    "number_of_words2 = len(Obama)\n",
    "print(number_of_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  words  counts\n",
      "0     ,     130\n",
      "1   the     126\n",
      "2     .     108\n",
      "3   and     105\n",
      "4    of      82\n",
      "5    to      66\n",
      "6   our      58\n",
      "7    we      50\n",
      "8  that      48\n",
      "9     a      47\n"
     ]
    }
   ],
   "source": [
    "fdist2 = nltk.FreqDist(Obama)\n",
    "ten_freq_table2 = pd.DataFrame(fdist2.most_common(10))\n",
    "ten_freq_table2.columns = ['words', 'counts']\n",
    "print(ten_freq_table2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>6. Do the same work without using NLTK</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('1789-Washington.txt') as f:\n",
    "    Washington2 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1431\n"
     ]
    }
   ],
   "source": [
    "Washington2_words = Washington2.split()\n",
    "print(len(Washington2_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   words  counts\n",
      "0    the     115\n",
      "1     of      71\n",
      "2    and      47\n",
      "3     to      46\n",
      "4  which      35\n",
      "5     in      28\n",
      "6      I      23\n",
      "7     be      23\n",
      "8     my      22\n",
      "9     by      19\n"
     ]
    }
   ],
   "source": [
    "count = Counter(Washington2_words)\n",
    "ten_freq_table3 = pd.DataFrame(count.most_common(10))\n",
    "ten_freq_table3.columns = ['words', 'counts']\n",
    "print(ten_freq_table3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>We can see that The only difference between this outcome and the nltk outcome is the punctuations. If we ignore the punctuations in the nltk outcome, the counts and most common words here are almost the same as in nltk</h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
